import streamlit as st
import librosa
import numpy as np
import joblib
import os
import io # C·∫ßn thi·∫øt ƒë·ªÉ ƒë·ªçc file audio t·ª´ b·ªô nh·ªõ
from audiorecorder import audiorecorder # Th∆∞ vi·ªán m·ªõi

# --- C·∫•u h√¨nh Trang (FE) ---
st.set_page_config(page_title="Nh·∫≠n d·∫°ng C·∫£m x√∫c", layout="wide")
st.title("üé§ ·ª®ng d·ª•ng Nh·∫≠n d·∫°ng C·∫£m x√∫c Gi·ªçng n√≥i (DSP501)")

# --- T·∫£i M√¥ h√¨nh (BE) ---
# (Ph·∫ßn n√†y gi·ªØ nguy√™n)
MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'models')
try:
    model = joblib.load(os.path.join(MODEL_PATH, "rf_emotion_model_v1.pkl"))
    scaler = joblib.load(os.path.join(MODEL_PATH, "scaler_v1.pkl"))
    encoder = joblib.load(os.path.join(MODEL_PATH, "encoder_v1.pkl"))
    st.sidebar.success("T·∫£i m√¥ h√¨nh (RF), Scaler, v√† Encoder th√†nh c√¥ng!")
except Exception as e:
    st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh: {e}")
    st.stop()

# --- H√†m Tr√≠ch xu·∫•t ƒê·∫∑c tr∆∞ng (BE) ---
# (H√†m n√†y gi·ªØ nguy√™n)
def extract_features(y, sr=22050):
    try:
        mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20).T, axis=0)
        rms = np.mean(librosa.feature.rms(y=y).T, axis=0)
        zcr = np.mean(librosa.feature.zero_crossing_rate(y=y).T, axis=0)
        features = np.hstack((mfccs, rms, zcr))
        return features
    except Exception as e:
        st.error(f"L·ªói khi tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng: {e}")
        return None

# --- H√†m X·ª≠ l√Ω v√† D·ª± ƒëo√°n (BE) ---
# (T√°ch logic n√†y ra h√†m ri√™ng ƒë·ªÉ c·∫£ 2 tab c√πng g·ªçi)
def process_and_predict(y, sr):
    with st.spinner("ƒêang ph√¢n t√≠ch t√≠n hi·ªáu (DSP) v√† ch·∫°y m√¥ h√¨nh AI..."):
        features = extract_features(y, sr)
        
        if features is not None:
            # Chu·∫©n b·ªã d·ªØ li·ªáu (reshape v√† scale)
            features_2d = features.reshape(1, -1)
            features_scaled = scaler.transform(features_2d)
            
            # D·ª± ƒëo√°n (AI/ML Model)
            prediction_encoded = model.predict(features_scaled)
            
            # Gi·∫£i m√£ k·∫øt qu·∫£ (Output)
            prediction_label = encoder.inverse_transform(prediction_encoded)[0]
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£ (FE)
            st.subheader("K·∫øt qu·∫£ Ph√¢n lo·∫°i:")
            st.success(f"C·∫£m x√∫c ƒë∆∞·ª£c d·ª± ƒëo√°n l√†: **{prediction_label.capitalize()}**")

# --- Giao di·ªán (FE) d√πng Tabs ---
tab1, tab2 = st.tabs(["üìÅ T·∫£i file l√™n", "üéôÔ∏è Thu √¢m tr·ª±c ti·∫øp"])

# ----- Tab 1: T·∫£i file l√™n -----
with tab1:
    st.header("Ph∆∞∆°ng th·ª©c 1: T·∫£i file √¢m thanh (.wav, .mp3)")
    uploaded_file = st.file_uploader("Ch·ªçn file √¢m thanh...", type=["wav", "mp3", "ogg"], key="file_uploader")

    if uploaded_file is not None:
        st.subheader("File √¢m thanh b·∫°n ƒë√£ t·∫£i l√™n:")
        st.audio(uploaded_file)
        
        # T·∫£i file √¢m thanh b·∫±ng Librosa
        y, sr = librosa.load(uploaded_file, sr=22050)
        
        # G·ªçi h√†m x·ª≠ l√Ω
        process_and_predict(y, sr)

# ----- Tab 2: Thu √¢m tr·ª±c ti·∫øp -----
with tab2:
    st.header("Ph∆∞∆°ng th·ª©c 2: Thu √¢m gi·ªçng n√≥i c·ªßa b·∫°n")
    st.write("B·∫•m n√∫t b√™n d∆∞·ªõi, n√≥i, sau ƒë√≥ b·∫•m d·ª´ng. App s·∫Ω ph√¢n t√≠ch sau khi b·∫°n b·∫•m d·ª´ng.")

    # Widget thu √¢m
    audio_bytes = audiorecorder(
        start_prompt="B·∫•m ƒë·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m ‚è∫Ô∏è",
        stop_prompt="B·∫•m ƒë·ªÉ d·ª´ng ghi √¢m ‚èπÔ∏è",
        pause_prompt="",
    )

    if audio_bytes:
        # Khi ng∆∞·ªùi d√πng b·∫•m d·ª´ng, audio_bytes s·∫Ω c√≥ d·ªØ li·ªáu
        st.subheader("B·∫£n thu √¢m c·ªßa b·∫°n:")
        st.audio(audio_bytes, format="audio/wav")

        # Chuy·ªÉn audio_bytes (d·ªØ li·ªáu th√¥) th√†nh m·ªôt file-like object
        # m√† Librosa c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c
        audio_file = io.BytesIO(audio_bytes)
        
        # T·∫£i file √¢m thanh t·ª´ b·ªô nh·ªõ
        y, sr = librosa.load(audio_file, sr=22050)
        
        # G·ªçi h√†m x·ª≠ l√Ω
        process_and_predict(y, sr)

# Th√¥ng tin sidebar
st.sidebar.info(
    "**Th√¥ng tin D·ª± √°n:**\n"
    "M√¥n h·ªçc: DSP501\n"
    "M√¥ h√¨nh: Random Forest (Accuracy: 56.60%)\n"
    "ƒê·∫∑c tr∆∞ng: MFCCs (20), Energy (1), ZCR (1)"
)