import streamlit as st
import librosa
import numpy as np
import joblib
import os
import io
from audiorecorder import audiorecorder
from scipy.signal import butter, lfilter # <-- THÃŠM Má»šI Äá»‚ Lá»ŒC

# --- Cáº¥u hÃ¬nh Trang (FE) ---
st.set_page_config(page_title="Nháº­n dáº¡ng Cáº£m xÃºc", layout="wide")
st.title("ðŸŽ¤ á»¨ng dá»¥ng Nháº­n dáº¡ng Cáº£m xÃºc Giá»ng nÃ³i (DSP501) - V2 (ÄÃ£ lá»c)")

# --- HÃ€M Lá»ŒC (THÃŠM Má»šI) ---
def butter_bandpass_filter(data, lowcut=100.0, highcut=8000.0, fs=22050, order=5):
    """
    HÃ m thiáº¿t káº¿ vÃ  Ã¡p dá»¥ng bá»™ lá»c bandpass Butterworth.
    """
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    y_filtered = lfilter(b, a, data)
    return y_filtered

# --- Táº£i MÃ´ hÃ¬nh (BE) - ÄÃƒ Cáº¬P NHáº¬T LÃŠN V2 ---
MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'models')
try:
    # Táº£i cÃ¡c file v2 má»›i
    model = joblib.load(os.path.join(MODEL_PATH, "rf_emotion_model_v2.pkl"))
    scaler = joblib.load(os.path.join(MODEL_PATH, "scaler_v2.pkl"))
    encoder = joblib.load(os.path.join(MODEL_PATH, "encoder_v2.pkl"))
    
    st.sidebar.success("Táº£i mÃ´ hÃ¬nh (RF v2), Scaler (v2), vÃ  Encoder (v2) thÃ nh cÃ´ng!")
except Exception as e:
    st.error(f"Lá»—i khi táº£i mÃ´ hÃ¬nh v2: {e}")
    st.stop()

# --- HÃ m TrÃ­ch xuáº¥t Äáº·c trÆ°ng (BE) - ÄÃƒ Cáº¬P NHáº¬T Äá»‚ Lá»ŒC ---
def extract_features(y, sr=22050):
    try:
        # 1. ÃP Dá»¤NG Bá»˜ Lá»ŒC (BÆ¯á»šC Má»šI)
        y_filtered = butter_bandpass_filter(y, fs=sr)
        
        # 2. TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« tÃ­n hiá»‡u ÄÃƒ Lá»ŒC (y_filtered)
        mfccs = np.mean(librosa.feature.mfcc(y=y_filtered, sr=sr, n_mfcc=20).T, axis=0)
        rms = np.mean(librosa.feature.rms(y=y_filtered).T, axis=0)
        zcr = np.mean(librosa.feature.zero_crossing_rate(y=y_filtered).T, axis=0)
        
        # 3. Káº¿t há»£p
        features = np.hstack((mfccs, rms, zcr))
        return features
    except Exception as e:
        st.error(f"Lá»—i khi trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng: {e}")
        return None

# --- HÃ m Xá»­ lÃ½ vÃ  Dá»± Ä‘oÃ¡n (BE) ---
# (HÃ m nÃ y giá»¯ nguyÃªn)
def process_and_predict(y, sr):
    with st.spinner("Äang Ã¡p dá»¥ng bá»™ lá»c (DSP), trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vÃ  cháº¡y mÃ´ hÃ¬nh AI..."):
        features = extract_features(y, sr)
        
        if features is not None:
            features_2d = features.reshape(1, -1)
            features_scaled = scaler.transform(features_2d)
            
            prediction_encoded = model.predict(features_scaled)
            prediction_label = encoder.inverse_transform(prediction_encoded)[0]
            
            st.subheader("Káº¿t quáº£ PhÃ¢n loáº¡i:")
            # Sá»­a láº¡i tÃªn class (loáº¡i bá» np.str_)
            prediction_label_str = str(prediction_label).replace("np.str_('", "").replace("')", "")
            st.success(f"Cáº£m xÃºc Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ : **{prediction_label_str.capitalize()}**")

# --- Giao diá»‡n (FE) dÃ¹ng Tabs ---
# (Pháº§n nÃ y giá»¯ nguyÃªn)
tab1, tab2 = st.tabs(["ðŸ“ Táº£i file lÃªn", "ðŸŽ™ï¸ Thu Ã¢m trá»±c tiáº¿p"])

with tab1:
    st.header("PhÆ°Æ¡ng thá»©c 1: Táº£i file Ã¢m thanh (.wav, .mp3)")
    uploaded_file = st.file_uploader("Chá»n file Ã¢m thanh...", type=["wav", "mp3", "ogg"], key="file_uploader")

    if uploaded_file is not None:
        st.subheader("File Ã¢m thanh báº¡n Ä‘Ã£ táº£i lÃªn:")
        st.audio(uploaded_file)
        
        y, sr = librosa.load(uploaded_file, sr=22050)
        process_and_predict(y, sr)

with tab2:
    st.header("PhÆ°Æ¡ng thá»©c 2: Thu Ã¢m giá»ng nÃ³i cá»§a báº¡n")
    st.write("Báº¥m nÃºt bÃªn dÆ°á»›i, nÃ³i, sau Ä‘Ã³ báº¥m dá»«ng. App sáº½ phÃ¢n tÃ­ch sau khi báº¡n báº¥m dá»«ng.")

    audio_bytes = audiorecorder(
        start_prompt="Báº¥m Ä‘á»ƒ báº¯t Ä‘áº§u ghi Ã¢m âºï¸",
        stop_prompt="Báº¥m Ä‘á»ƒ dá»«ng ghi Ã¢m â¹ï¸",
        pause_prompt="",
    )

    if audio_bytes:
        st.subheader("Báº£n thu Ã¢m cá»§a báº¡n:")
        st.audio(audio_bytes, format="audio/wav")
        audio_file = io.BytesIO(audio_bytes)
        
        y, sr = librosa.load(audio_file, sr=22050)
        process_and_predict(y, sr)

# --- Sidebar (ÄÃƒ Cáº¬P NHáº¬T) ---
st.sidebar.info(
    "**ThÃ´ng tin Dá»± Ã¡n:**\n"
    "MÃ´n há»c: DSP501\n"
    "MÃ´ hÃ¬nh: Random Forest (v2 - ÄÃ£ lá»c)\n"
    "Äá»™ chÃ­nh xÃ¡c: **57.99%**\n"
    "Äáº·c trÆ°ng: Filtered MFCCs (20), Energy (1), ZCR (1)"
)