# ğŸš€ Dá»± Ã¡n DSP501: Nháº­n dáº¡ng Cáº£m xÃºc Giá»ng nÃ³i

ÄÃ¢y lÃ  dá»± Ã¡n cuá»‘i ká»³ cho mÃ´n há»c DSP501, tÃ­ch há»£p cÃ¡c ká»¹ thuáº­t Xá»­ lÃ½ TÃ­n hiá»‡u Sá»‘ (DSP) vá»›i TrÃ­ tuá»‡ NhÃ¢n táº¡o (AI) Ä‘á»ƒ phÃ¢n loáº¡i cáº£m xÃºc tá»« tÃ­n hiá»‡u giá»ng nÃ³i.

## ğŸ“‹ Quy trÃ¬nh Há»‡ thá»‘ng (System Workflow)

Dá»± Ã¡n tuÃ¢n thá»§ theo quy trÃ¬nh 5 bÆ°á»›c Ä‘Æ°á»£c yÃªu cáº§u trong Ä‘á» bÃ i:

**Signal Input â†’ Preprocessing (DSP) â†’ Feature Extraction â†’ AI/ML Model â†’ Classification Output**

## âœ¨ TÃ­nh nÄƒng

* Xá»­ lÃ½ vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng DSP (MFCCs, Energy, ZCR, Mel Spectrogram) tá»« file Ã¢m thanh.
* Huáº¥n luyá»‡n vÃ  so sÃ¡nh 3 mÃ´ hÃ¬nh AI/ML (SVM, Random Forest, CNN).
* Giáº£i quyáº¿t váº¥n Ä‘á» Overfitting cá»§a CNN báº±ng Early Stopping.
* Cung cáº¥p má»™t Web App Demo (Front-End) báº±ng Streamlit.
* Há»— trá»£ dá»± Ä‘oÃ¡n tá»« cáº£ file táº£i lÃªn vÃ  thu Ã¢m trá»±c tiáº¿p.

---

## âš™ï¸ CÃ i Ä‘áº·t vÃ  YÃªu cáº§u Há»‡ thá»‘ng

Äá»ƒ cháº¡y dá»± Ã¡n nÃ y, báº¡n cáº§n cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n Python VÃ€ cÃ¡c pháº§n má»m bÃªn ngoÃ i (FFmpeg, CUDA).

### 1. YÃªu cáº§u Báº¯t buá»™c (BÃªn ngoÃ i)

ÄÃ¢y lÃ  cÃ¡c pháº§n má»m pháº£i Ä‘Æ°á»£c cÃ i Ä‘áº·t trÃªn há»‡ thá»‘ng cá»§a báº¡n trÆ°á»›c.

**a) Python (Quan trá»ng)**
* Dá»± Ã¡n nÃ y **báº¯t buá»™c** pháº£i sá»­ dá»¥ng **Python 3.x.x**.

**b) FFmpeg (Báº¯t buá»™c cho Demo)**
* ThÆ° viá»‡n thu Ã¢m (`streamlit-audiorecorder`) yÃªu cáº§u FFmpeg Ä‘á»ƒ xá»­ lÃ½ file audio tá»« trÃ¬nh duyá»‡t.
* **CÃ¡ch cÃ i:**
    1.  Táº£i báº£n "essentials build" tá»«: [https://www.gyan.dev/ffmpeg/builds/](https://www.gyan.dev/ffmpeg/builds/)
    2.  Giáº£i nÃ©n vÃ  Ä‘áº·t thÆ° má»¥c `ffmpeg` vÃ o `C:\ffmpeg`.
    3.  ThÃªm Ä‘Æ°á»ng dáº«n `C:\ffmpeg\bin` vÃ o Biáº¿n mÃ´i trÆ°á»ng (Environment Variables) `PATH` cá»§a há»‡ thá»‘ng.
    4.  Khá»Ÿi Ä‘á»™ng láº¡i Terminal vÃ  gÃµ `ffmpeg -version` Ä‘á»ƒ kiá»ƒm tra.

### 2. YÃªu cáº§u TÃ¹y chá»n (TÄƒng tá»‘c GPU)

Náº¿u báº¡n muá»‘n huáº¥n luyá»‡n mÃ´ hÃ¬nh CNN (Notebook 04) báº±ng GPU, báº¡n **báº¯t buá»™c** pháº£i cÃ i "cÃ´ng thá»©c" sau:

* **GPU Driver:** NVIDIA Driver (phiÃªn báº£n má»›i nháº¥t).
* **TensorFlow:** `2.20.0` (Ä‘Ã£ cÃ³ trong `requirements.txt`).
* **CUDA Toolkit:** **12.3** (KhÃ´ng pháº£i 13.0).
* **cuDNN:** **8.9** (cho CUDA 12.x).
* Pháº£i cháº¡y á»Ÿ WSL2 do tá»« tf 2.10 trá»Ÿ lÃªn tf Ä‘Ã£ khÃ´ng há»— trá»£ native windown

### 3. CÃ i Ä‘áº·t MÃ´i trÆ°á»ng Python

1.  **Clone dá»± Ã¡n (Náº¿u cÃ³):**
    ```bash
    git clone [your-repo-link]
    cd DSP501_SpeechEmotionRecognition
    ```

2.  **Táº¡o mÃ´i trÆ°á»ng áº£o (DÃ¹ng Python 3.x):**
    ```bash
    py -3.x -m venv venv
    ```

3.  **KÃ­ch hoáº¡t mÃ´i trÆ°á»ng:**
    ```bash
    .\venv\Scripts\activate
    ```

4.  **CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n Python:**
    ```bash
    pip install -r requirements.txt
    ```

---

## ğŸš€ HÆ°á»›ng dáº«n Cháº¡y Dá»± Ã¡n

Báº¡n cÃ³ hai lá»±a chá»n: (1) Cháº¡y Demo Ä‘á»ƒ xem káº¿t quáº£, hoáº·c (2) Huáº¥n luyá»‡n láº¡i tá»« Ä‘áº§u.

### 1. CÃ¡ch cháº¡y Demo (Nhanh nháº¥t)

CÃ¡ch nÃ y sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n (trong thÆ° má»¥c `models/`). Äáº£m báº£o báº¡n Ä‘Ã£ cÃ i **FFmpeg**.

1.  KÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o:
    ```bash
    .\venv\Scripts\activate
    ```
2.  Di chuyá»ƒn vÃ o thÆ° má»¥c `app`:
    ```bash
    cd app
    ```
3.  Cháº¡y á»©ng dá»¥ng Streamlit:
    ```bash
    streamlit run app.py
    ```
4.  TrÃ¬nh duyá»‡t sáº½ tá»± Ä‘á»™ng má»Ÿ. Báº¡n cÃ³ thá»ƒ Táº£i file hoáº·c Thu Ã¢m.

### 2. CÃ¡ch Huáº¥n luyá»‡n láº¡i MÃ´ hÃ¬nh (Tá»« Ä‘áº§u)

Náº¿u báº¡n muá»‘n tá»± mÃ¬nh cháº¡y láº¡i toÃ n bá»™ quy trÃ¬nh:

1.  **Táº£i Dá»¯ liá»‡u:**
    * Táº£i bá»™ dá»¯ liá»‡u **RAVDESS** (chá»‰ cáº§n file `Audio_Speech_Actors_01-24.zip`).
    * Giáº£i nÃ©n 24 thÆ° má»¥c (Actor_01...) vÃ o thÆ° má»¥c `data/raw/`.

2.  **Cháº¡y Notebooks (theo thá»© tá»±):**
    * **(KhÃ¡m phÃ¡)** `notebooks/01_data_exploration.ipynb`: Äá»ƒ xem dá»¯ liá»‡u vÃ  spectrogram.
    * **(TrÃ­ch xuáº¥t cho SVM/RF)** `notebooks/02_feature_extraction.ipynb`: Cháº¡y toÃ n bá»™ Ä‘á»ƒ táº¡o file `data/processed/features.npy` vÃ  `labels.npy`.
    * **(Huáº¥n luyá»‡n SVM/RF)** `notebooks/03_model_training.ipynb`: Cháº¡y toÃ n bá»™ Ä‘á»ƒ huáº¥n luyá»‡n, Ä‘Ã¡nh giÃ¡ vÃ  lÆ°u cÃ¡c file mÃ´ hÃ¬nh (`.pkl`) vÃ o thÆ° má»¥c `models/`. **Demo sá»­ dá»¥ng mÃ´ hÃ¬nh nÃ y.**
    * **(TrÃ­ch xuáº¥t & Huáº¥n luyá»‡n CNN)** `notebooks/04_cnn_model.ipynb`: Cháº¡y toÃ n bá»™ Ä‘á»ƒ trÃ­ch xuáº¥t spectrogram (X_cnn.npy) vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh CNN (vá»›i Early Stopping).
    * **(Kiá»ƒm tra Lá»c)** `notebooks/05_filtering.ipynb`: Cháº¡y Ä‘á»ƒ xÃ¡c nháº­n yÃªu cáº§u lá»c Bandpass.

---

## ğŸ“‚ Cáº¥u trÃºc ThÆ° má»¥c
```
DSP501_SpeechEmotionRecognition/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py                    # Streamlit demo
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Dá»¯ liá»‡u gá»‘c RAVDESS (Actor_01...)
â”‚   â””â”€â”€ processed/                # File Ä‘Ã£ xá»­ lÃ½ (.npy: features, labels, X_cnnâ€¦)
â”œâ”€â”€ deliverables/                 # BÃ¡o cÃ¡o, slide, video ná»™p bÃ i
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ rf_emotion_model_v1.pkl   # MÃ´ hÃ¬nh Random Forest dÃ¹ng cho Demo
â”‚   â””â”€â”€ (cÃ¡c file mÃ´ hÃ¬nh khÃ¡c: .pkl, .h5, ...)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_extraction.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â”œâ”€â”€ 04_cnn_model.ipynb
â”‚   â””â”€â”€ 05_filtering.ipynb
â”œâ”€â”€ results/                      # Biá»ƒu Ä‘á»“, hÃ¬nh áº£nh vÃ  káº¿t quáº£ Ä‘á»ƒ chÃ¨n vÃ o bÃ¡o cÃ¡o
â”œâ”€â”€ requirements.txt              # Danh sÃ¡ch thÆ° viá»‡n Python
â””â”€â”€ README.md                     # HÆ°á»›ng dáº«n dá»± Ã¡n
```